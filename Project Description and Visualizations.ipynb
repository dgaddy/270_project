{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS270 Final Project\n",
    "\n",
    "#### David Gaddy, Samee Ibraheem, and Daniel Filan\n",
    "\n",
    "## Overview\n",
    "\n",
    "For our project, we implemented a dual decomposition algorithm for machine translation\n",
    "alignments. The alignment process of machine translation tries to find words in one language\n",
    "that correspond to words in another. Typical alignment models are asymmetric, so aligning\n",
    "language 1 to language 2 is not the same as aligning language 2 to language 2, however we\n",
    "would prefer if our alignments agreed in both directions. The paper *Model-Based Aligner\n",
    "Combination Using Dual Decomposition* by John DeNero and Klaus Macherey uses a dual\n",
    "decomposition algorithm to encourage agreement between the two directions. This algorithm\n",
    "allows us to do effecient approximate inference while encouraging agreement by using dual\n",
    "variables from a Lagragian relaxation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "The code for our implementation is the in the file `our_align_dual.py`.  In this jupyter notebook, we will demonstrate some results that we got with our implementation.\n",
    "\n",
    "First, let us load a model we trained on an English-French parallel corpus of 10,000 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from our_align_dual import *\n",
    "\n",
    "t_ef, q_ef = load_model('small_models_fr/ef_model.pkl.ibm1')\n",
    "t_fe, q_fe = load_model('small_models_fr/fe_model.pkl.ibm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "We have two models, one for each direction English->French and French->English.  Without dual decomposition, we can use each of these directions separately or take the intersection of the aligments suggested by each directional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection over union 0.4040338321405335\n",
      "direction 1\n",
      "Ref=1009\tTest=1135\tMatchRef=627\tMatchTest=691\n",
      "Prec=60.88\tRec=62.14\tAER=38.50\n",
      "direction 2\n",
      "Ref=1009\tTest=1023\tMatchRef=612\tMatchTest=674\n",
      "Prec=65.88\tRec=60.65\tAER=36.84\n",
      "intersection\n",
      "Ref=1009\tTest=621\tMatchRef=534\tMatchTest=561\n",
      "Prec=90.34\tRec=52.92\tAER=33.25\n"
     ]
    }
   ],
   "source": [
    "dev_files = {'en':'fr_data/en-fr.en', 'f':'fr_data/en-fr.fr'}\n",
    "gold_file = 'fr_data/en-fr.align'\n",
    "reverse_output = False\n",
    "\n",
    "en_sent = load_sentences(dev_files['en'])\n",
    "f_sent = load_sentences(dev_files['f'])\n",
    "\n",
    "dir1_alignments = []\n",
    "dir2_alignments = []\n",
    "intersection_alignments = []\n",
    "union_alignments = []\n",
    "num_intersection = 0\n",
    "num_union = 0\n",
    "for i in range(len(en_sent)):\n",
    "    # aligns each foreign word to the english one\n",
    "    align_ef = align_ibm(en_sent[i], f_sent[i], t_ef, q_ef)\n",
    "    align_ef = filter_null_alignments([(ei,fi) for fi,ei in enumerate(align_ef)])\n",
    "    # aligns each english word to a foreign one\n",
    "    align_fe = align_ibm(f_sent[i], en_sent[i], t_fe, q_fe)\n",
    "    align_fe = filter_null_alignments([(ei,fi) for ei,fi in enumerate(align_fe)])\n",
    "\n",
    "    dir1_alignments.append(align_ef)\n",
    "    dir2_alignments.append(align_fe)\n",
    "\n",
    "    intersection = combine_intersect(align_ef, align_fe)\n",
    "    union = combine_union(align_ef, align_fe)\n",
    "    num_intersection += len(intersection)\n",
    "    num_union += len(union)\n",
    "    intersection_alignments.append(intersection)\n",
    "    union_alignments.append(union)\n",
    "print('intersection over union', num_intersection / num_union)\n",
    "\n",
    "save_alignments(dir1_alignments, 'ibm-align-dir1.txt', reverse_output)\n",
    "save_alignments(dir2_alignments, 'ibm-align-dir2.txt', reverse_output)\n",
    "save_alignments(intersection_alignments, 'ibm-align-intersection.txt', reverse_output)\n",
    "save_alignments(union_alignments, 'ibm-align-union.txt', reverse_output)\n",
    "print('direction 1')\n",
    "!perl measure-alignment-error.pl fr_data/en-fr.align ibm-align-dir1.txt\n",
    "print('direction 2')\n",
    "!perl measure-alignment-error.pl fr_data/en-fr.align ibm-align-dir2.txt\n",
    "print('intersection')\n",
    "!perl measure-alignment-error.pl fr_data/en-fr.align ibm-align-intersection.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two numbers we will focus on are labeled *intersection over union* and *AER*.  Intersection over union is a metric for how much the alignments agree between the two directions.  Higher is better, and a value of 1 would indicate perfect agreement.  AER, or alignment error rate, is a measure of how much the final alignments agree with alignments annotated by people who know both languages.  Lower AER is better.  The intersected alignment baseline gets an AER of 33.25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual Decomposition\n",
    "\n",
    "Dual decomposition is a method of encouraging alignments from the two different model directions to agree.  It uses Lagrange multipliers to enforce the agreement.  These Lagrange multipliers end up being combined with the model in a way that allows us to run the same inference procedure we would typically use but with slightly modified model probabilities.\n",
    "\n",
    "Let's look at how dual decomposition affects our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection over union 0.5144927536231884\n",
      "converged 0.02\n",
      "Ref=1009\tTest=781\tMatchRef=574\tMatchTest=623\r\n",
      "Prec=79.77\tRec=56.89\tAER=33.59\r\n"
     ]
    }
   ],
   "source": [
    "alignments = []\n",
    "num_converged = 0\n",
    "num_intersection = 0\n",
    "num_union = 0\n",
    "for i in range(len(en_sent)):\n",
    "    intersection, union, converged = align_dual(en_sent[i], f_sent[i], t_ef, t_fe, q_ef, q_fe, 1, 250)\n",
    "    intersection = filter_null_alignments(intersection)\n",
    "    union = filter_null_alignments(union)\n",
    "\n",
    "    num_intersection += len(intersection)\n",
    "    num_union += len(union)\n",
    "    alignments.append(intersection)\n",
    "    if converged:\n",
    "        num_converged += 1\n",
    "print('intersection over union',num_intersection / num_union)\n",
    "print('converged',float(num_converged) / len(en_sent))\n",
    "\n",
    "save_alignments(alignments, 'dual-decomp-intersection.txt', reverse_output)\n",
    "!perl measure-alignment-error.pl fr_data/en-fr.align dual-decomp-intersection.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the intersection over union increased significantly, which means that we were successful in encouraging agreement between the two directions.  The AER is slightly worse, though, which means increasing agreement didn't cause the alignments to agree more with human annotations.\n",
    "\n",
    "One thing to note is that the convergence rate, or percentage of time where the two directions completely agree after dual decomposition, is very low.  Dual decomposition is an iterative algorithm, and given infinite time, it should converge 100% of the time.  However, the convergence can be very slow, and we cut off the algorithm after 250 iterations.  Even without having converged, though, we can see that it has significantly increased agreement."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
